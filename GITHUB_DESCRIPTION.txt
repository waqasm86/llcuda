CUDA-accelerated LLM inference for Python - Pure Python package for easy installation on Kaggle, Colab, and all platforms. Works with llama-server backend for high-performance GPU inference.
